import os
import math
import subprocess
import json
import re
import time
from typing import List, Dict
from openai import OpenAI
from .subtitle_translator import SubtitleTranslator


class AudioTranslator:
    def __init__(self, api_key: str):
        """éŸ³é¢‘è½¬å­—å¹•ç¿»è¯‘å™¨"""
        self.client = OpenAI(api_key=api_key)
        self.subtitle_translator = SubtitleTranslator()
        self._setup_ffmpeg_path()

    def _setup_ffmpeg_path(self):
        """è®¾ç½®FFmpegè·¯å¾„"""
        # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•çš„ffmpegè·¯å¾„
        current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        ffmpeg_bin = os.path.join(current_dir, "ffmpeg", "bin")

        if os.path.exists(ffmpeg_bin) and ffmpeg_bin not in os.environ.get('PATH', ''):
            os.environ['PATH'] = ffmpeg_bin + os.pathsep + os.environ.get('PATH', '')
            print(f"è®¾ç½®FFmpegè·¯å¾„: {ffmpeg_bin}")

    def check_ffmpeg(self):
        """æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(['ffmpeg', '-version'],
                                    capture_output=True, text=True,
                                    encoding='utf-8', errors='ignore', timeout=10)
            return result.returncode == 0
        except Exception as e:
            print(f"æ£€æŸ¥FFmpegå¤±è´¥: {e}")
            return False

    def get_video_duration(self, video_path: str) -> float:
        """è·å–è§†é¢‘æ—¶é•¿"""
        cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', video_path]

        try:
            result = subprocess.run(cmd, capture_output=True, text=True,
                                    encoding='utf-8', errors='ignore', timeout=30)
            if result.returncode != 0:
                print(f"è·å–è§†é¢‘æ—¶é•¿å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                return None

            if not result.stdout.strip():
                print("ffprobeæœªè¿”å›è§†é¢‘æ ¼å¼ä¿¡æ¯")
                return None

            info = json.loads(result.stdout)
            duration = info.get('format', {}).get('duration')
            if duration:
                return float(duration)
            else:
                print("æ— æ³•ä»è§†é¢‘ä¿¡æ¯ä¸­è·å–æ—¶é•¿")
                return None

        except json.JSONDecodeError as e:
            print(f"è§£æè§†é¢‘ä¿¡æ¯JSONæ—¶å‡ºé”™: {e}")
            return None
        except Exception as e:
            print(f"è·å–è§†é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return None

    def extract_audio_chunks(self, video_path: str, chunk_duration: int = 180) -> List[Dict]:
        """æå–éŸ³é¢‘åˆ†æ®µ"""
        total_duration = self.get_video_duration(video_path)
        if not total_duration:
            print("æ— æ³•è·å–è§†é¢‘æ—¶é•¿")
            return []

        # åˆ›å»ºä¸´æ—¶éŸ³é¢‘ç›®å½•
        output_dir = "temp_audio"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        num_chunks = math.ceil(total_duration / chunk_duration)
        audio_chunks = []

        print(f"è§†é¢‘æ€»æ—¶é•¿: {total_duration:.1f}ç§’ï¼Œå°†åˆ†å‰²ä¸º {num_chunks} æ®µ")

        for i in range(num_chunks):
            start_time = i * chunk_duration
            end_time = min((i + 1) * chunk_duration, total_duration)
            duration = end_time - start_time

            chunk_path = os.path.join(output_dir, f"chunk_{i:03d}.mp3")

            cmd = [
                'ffmpeg', '-i', video_path,
                '-ss', str(start_time), '-t', str(duration),
                '-vn', '-acodec', 'mp3', '-ar', '16000', '-ac', '1',
                '-y', chunk_path
            ]

            try:
                print(f"æå–éŸ³é¢‘æ®µ {i + 1}/{num_chunks}: {start_time:.1f}s - {end_time:.1f}s")
                result = subprocess.run(cmd, capture_output=True, text=True,
                                        encoding='utf-8', errors='ignore', timeout=60)

                if result.returncode == 0 and os.path.exists(chunk_path):
                    file_size = os.path.getsize(chunk_path)
                    if file_size > 1000:  # æ–‡ä»¶å¤§å°å¤§äº1KBæ‰è®¤ä¸ºæœ‰æ•ˆ
                        audio_chunks.append({
                            'path': chunk_path,
                            'start_time': start_time,
                            'end_time': end_time,
                            'chunk_index': i
                        })
                    else:
                        print(f"  éŸ³é¢‘æ®µ {i + 1} æ–‡ä»¶è¿‡å°ï¼Œè·³è¿‡")
                        if os.path.exists(chunk_path):
                            os.remove(chunk_path)
                else:
                    print(f"  éŸ³é¢‘æ®µ {i + 1} æå–å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                    if result.stderr:
                        print(f"  é”™è¯¯ä¿¡æ¯: {result.stderr}")

            except Exception as e:
                print(f"æå–éŸ³é¢‘æ®µ {i + 1} å¤±è´¥: {e}")
                continue

        print(f"æˆåŠŸæå– {len(audio_chunks)} ä¸ªæœ‰æ•ˆéŸ³é¢‘æ®µ")
        return audio_chunks

    def transcribe_audio_chunk(self,audio_model:str, audio_path: str, chunk_start_time: float) -> List[Dict]:
        """è½¬å½•å•ä¸ªéŸ³é¢‘æ®µ"""
        try:
            with open(audio_path, "rb") as audio_file:
                transcription = self.client.audio.transcriptions.create(
                    model=audio_model,
                    file=audio_file,
                    response_format="verbose_json",
                    timestamp_granularities=["segment"]
                )

                segments = []
                if hasattr(transcription, 'segments') and transcription.segments:
                    for segment in transcription.segments:
                        start_time = chunk_start_time + segment.start
                        end_time = chunk_start_time + segment.end
                        text = segment.text.strip()

                        if text:
                            segments.append({
                                'start_time': start_time,
                                'end_time': end_time,
                                'text': text
                            })

                return segments

        except Exception as e:
            print(f"è½¬å½•éŸ³é¢‘å¤±è´¥: {e}")
            return []

    def detect_embedded_subtitles(self, video_path: str) -> List[Dict]:
        """æ£€æµ‹è§†é¢‘å†…å°å­—å¹•"""
        cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_streams', video_path]

        try:
            # æ˜ç¡®æŒ‡å®šç¼–ç æ–¹å¼é¿å…Windowsç¼–ç é—®é¢˜
            result = subprocess.run(cmd, capture_output=True, text=True,
                                    encoding='utf-8', errors='ignore', timeout=30)

            if result.returncode != 0:
                print(f"ffprobeæ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                if result.stderr:
                    print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
                return []

            if not result.stdout.strip():
                print("ffprobeæœªè¿”å›ä»»ä½•è¾“å‡º")
                return []

            info = json.loads(result.stdout)
            subtitle_streams = []

            for stream in info.get('streams', []):
                if stream.get('codec_type') == 'subtitle':
                    subtitle_streams.append({
                        'index': stream.get('index'),
                        'language': stream.get('tags', {}).get('language', 'unknown'),
                        'codec': stream.get('codec_name', 'unknown'),
                        'title': stream.get('tags', {}).get('title', '')
                    })

            return subtitle_streams

        except json.JSONDecodeError as e:
            print(f"è§£æJSONæ—¶å‡ºé”™: {e}")
            print(f"ffprobeè¾“å‡º: {result.stdout[:500] if 'result' in locals() else 'N/A'}")
            return []
        except Exception as e:
            print(f"æ£€æµ‹å†…å°å­—å¹•æ—¶å‡ºé”™: {e}")
            return []

    def extract_embedded_subtitles(self, video_path: str, output_path: str = None) -> str:
        """æå–å†…å°å­—å¹•ä¸ºSRTæ–‡ä»¶"""
        subtitle_streams = self.detect_embedded_subtitles(video_path)

        if not subtitle_streams:
            print("æœªæ£€æµ‹åˆ°å†…å°å­—å¹•")
            return None

        print(f"æ£€æµ‹åˆ° {len(subtitle_streams)} ä¸ªå­—å¹•æµ")
        for i, stream in enumerate(subtitle_streams):
            lang = stream['language']
            codec = stream['codec']
            title = stream['title']
            print(f"  {i + 1}. è¯­è¨€: {lang}, ç¼–ç : {codec}, æ ‡é¢˜: {title}")

        # é€‰æ‹©ç¬¬ä¸€ä¸ªå­—å¹•æµ
        selected_stream = subtitle_streams[0]
        stream_index = selected_stream['index']

        # è®¾ç½®è¾“å‡ºè·¯å¾„
        if not output_path:
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            output_path = f"temp_{base_name}_extracted.srt"

        # æå–å­—å¹• - ä½¿ç”¨æµçš„ç»å¯¹ç´¢å¼•
        cmd = [
            'ffmpeg', '-i', video_path,
            '-map', f'0:{stream_index}',  # ä½¿ç”¨ç»å¯¹æµç´¢å¼•è€Œä¸æ˜¯å­—å¹•æµç´¢å¼•
            '-c:s', 'srt',
            '-y', output_path
        ]

        try:
            print(f"æ­£åœ¨æå–å†…å°å­—å¹•...")
            result = subprocess.run(cmd, capture_output=True, text=True,
                                    encoding='utf-8', errors='ignore', timeout=60)

            if result.returncode == 0 and os.path.exists(output_path):
                # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶æ˜¯å¦æœ‰å†…å®¹
                if os.path.getsize(output_path) > 0:
                    print("å†…å°å­—å¹•æå–æˆåŠŸ")
                    return output_path
                else:
                    print("å­—å¹•æ–‡ä»¶ä¸ºç©º")
                    if os.path.exists(output_path):
                        os.remove(output_path)
                    return None
            else:
                print(f"å­—å¹•æå–å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                if result.stderr:
                    print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
                return None

        except Exception as e:
            print(f"æå–å­—å¹•æ—¶å‡ºé”™: {e}")
            return None

    def seconds_to_srt_time(self, seconds: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        milliseconds = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"

    def segments_to_srt_format(self, segments: List[Dict]) -> List[Dict]:
        """å°†è½¬å½•æ®µè½è½¬æ¢ä¸ºSRTæ ¼å¼"""
        srt_subtitles = []

        for i, segment in enumerate(segments, 1):
            start_time = self.seconds_to_srt_time(segment['start_time'])
            end_time = self.seconds_to_srt_time(segment['end_time'])

            srt_subtitles.append({
                'index': i,
                'timeline': f"{start_time} --> {end_time}",
                'text': segment['text']
            })

        return srt_subtitles

    def cleanup_temp_files(self, audio_chunks: List[Dict]):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            for chunk_info in audio_chunks:
                if os.path.exists(chunk_info['path']):
                    os.remove(chunk_info['path'])

            temp_dir = "temp_audio"
            if os.path.exists(temp_dir) and not os.listdir(temp_dir):
                os.rmdir(temp_dir)

        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")


def generate_subtitles(video_path: str, api_key: str, text_models:str,audio_models:str, output_path: str = "output",
                       mode: str = "auto", translation_type: str = "åŒè¯­",
                       batch_size: int = 10, batch_min: int = 3) -> str:
    """
    ç”Ÿæˆè§†é¢‘å­—å¹•å¹¶ç¿»è¯‘

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        api_key: OpenAI APIå¯†é’¥
        output_path: è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
        mode: å¤„ç†æ¨¡å¼ ("auto" æˆ– "ç¿»è¯‘å†…")
        translation_type: ç¿»è¯‘ç±»å‹ ("åŒè¯­", "è‹±æ–‡", "ä¸­æ–‡")
        batch_size: æ‰¹é‡ç¿»è¯‘å¤§å°
        batch_min: æœ€å°æ‰¹é‡å¤§å°

    Returns:
        ç”Ÿæˆçš„å­—å¹•æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
    """

    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return None

    # åˆ›å»ºç¿»è¯‘å™¨
    translator = AudioTranslator(api_key)

    # æ£€æŸ¥FFmpeg
    if not translator.check_ffmpeg():
        print("FFmpegä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        return None

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_path, exist_ok=True)

    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    output_file = os.path.join(output_path, f"{video_name}_{translation_type}_audio.srt")

    try:
        if mode == "åªç¿»å†…å°":
            # æ¨¡å¼1: ç¿»è¯‘å†…å°å­—å¹•
            print("ğŸ” æ¨¡å¼: ç¿»è¯‘å†…å°å­—å¹•")

            # æ£€æµ‹å†…å°å­—å¹•
            embedded_subs = translator.detect_embedded_subtitles(video_path)
            if not embedded_subs:
                print("æœªæ£€æµ‹åˆ°å†…å°å­—å¹•ï¼Œæ— æ³•ä½¿ç”¨æ­¤æ¨¡å¼")
                return "æœªæ£€æµ‹åˆ°å†…å°å­—å¹•ï¼Œæ— æ³•ä½¿ç”¨æ­¤æ¨¡å¼"

            # æå–å†…å°å­—å¹•
            temp_srt = translator.extract_embedded_subtitles(video_path)
            if not temp_srt:
                print("å†…å°å­—å¹•æå–å¤±è´¥")
                return "å†…å°å­—å¹•æå–å¤±è´¥"

            # è§£æSRTæ–‡ä»¶
            subtitles = translator.subtitle_translator.parse_srt(open(temp_srt, 'r', encoding='utf-8').read())
            if not subtitles:
                print("å­—å¹•è§£æå¤±è´¥")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_srt):
                    os.remove(temp_srt)
                return "å­—å¹•è§£æå¤±è´¥"

            print(f"æˆåŠŸè§£æ {len(subtitles)} æ¡å­—å¹•")

            # ç¿»è¯‘å­—å¹•
            print("ğŸŒ å¼€å§‹ç¿»è¯‘å­—å¹•...")

            # æå–æ–‡æœ¬è¿›è¡Œç¿»è¯‘
            texts = [sub['text'] for sub in subtitles]

            # åˆ†æ‰¹ç¿»è¯‘
            translated_texts = []
            total_batches = (len(texts) + batch_size - 1) // batch_size

            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i + batch_size]
                current_batch = i // batch_size + 1

                print(f"æ­£åœ¨ç¿»è¯‘ç¬¬ {current_batch}/{total_batches} æ‰¹æ¬¡ï¼ŒåŒ…å« {len(batch_texts)} æ¡å­—å¹•...")

                # ä½¿ç”¨æˆ‘ä»¬ä¹‹å‰å†™çš„ç¿»è¯‘å‡½æ•°
                if len(batch_texts) >= batch_min:
                    translated_batch = translator.subtitle_translator.translate_texts_batch(
                        api_key=api_key,
                        model=text_models,
                        texts=batch_texts,
                        translation_type=translation_type
                    )
                else:
                    # å¦‚æœæ‰¹æ¬¡å¤ªå°ï¼Œé€æ¡ç¿»è¯‘
                    translated_batch = translator.subtitle_translator._translate_one_by_one(
                        api_key=api_key,
                        model=text_models,
                        texts=batch_texts,
                        translation_type=translation_type,
                        max_retries=3
                    )

                translated_texts.extend(translated_batch)
                time.sleep(0.5)  # é¿å…APIè¯·æ±‚è¿‡é¢‘

            # æ ¼å¼åŒ–ç¿»è¯‘ç»“æœ
            for i, subtitle in enumerate(subtitles):
                if i < len(translated_texts):
                    formatted_text = translator.subtitle_translator.format_translated_subtitle(
                        subtitle['text'], translated_texts[i], translation_type
                    )
                    subtitle['text'] = formatted_text

            # ç”ŸæˆSRTæ–‡ä»¶
            srt_content = translator.subtitle_translator.generate_srt(subtitles)

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_srt):
                os.remove(temp_srt)

        elif mode == "auto":
            # æ¨¡å¼2: è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹å¼
            print("ğŸ¤– æ¨¡å¼: è‡ªåŠ¨é€‰æ‹©")

            # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰å†…å°å­—å¹•
            embedded_subs = translator.detect_embedded_subtitles(video_path)

            if embedded_subs:
                print("æ£€æµ‹åˆ°å†…å°å­—å¹•ï¼Œä¼˜å…ˆä½¿ç”¨å†…å°å­—å¹•ç¿»è¯‘")
                # é€’å½’è°ƒç”¨ç¿»è¯‘å†…å°å­—å¹•æ¨¡å¼
                return generate_subtitles(
                    video_path=video_path,
                    api_key=api_key,
                    output_path=output_path,
                    mode="åªç¿»å†…å°",
                    translation_type=translation_type,
                    batch_size=batch_size,
                    batch_min=batch_min
                )

            # æ²¡æœ‰å†…å°å­—å¹•ï¼Œä½¿ç”¨è¯­éŸ³è½¬å½•
            print("æœªæ£€æµ‹åˆ°å†…å°å­—å¹•ï¼Œä½¿ç”¨è¯­éŸ³è½¬å½•æ¨¡å¼")
            print("ğŸ¤ å¼€å§‹è¯­éŸ³è½¬å½•...")

            # æå–éŸ³é¢‘åˆ†æ®µ
            audio_chunks = translator.extract_audio_chunks(video_path, chunk_duration=180)
            if not audio_chunks:
                print("éŸ³é¢‘æå–å¤±è´¥")
                return None

            # è½¬å½•æ‰€æœ‰éŸ³é¢‘æ®µï¼Œä¿æŒåˆ†æ®µç»“æ„
            audio_segments_groups = []
            for i, chunk_info in enumerate(audio_chunks):
                print(f"ğŸ¤ è½¬å½•ç¬¬ {i + 1}/{len(audio_chunks)} æ®µ...")

                segments = translator.transcribe_audio_chunk(
                    audio_models,
                    chunk_info['path'],
                    chunk_info['start_time'],

                )

                if segments:
                    audio_segments_groups.append(segments)
                    print(f"  è·å¾— {len(segments)} ä¸ªè¯­éŸ³æ®µè½")
                else:
                    print("  è¯¥æ®µæ— è¯­éŸ³å†…å®¹")
                    audio_segments_groups.append([])  # ä¿æŒåˆ†ç»„ç»“æ„

            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„è½¬å½•ç»“æœ
            total_segments = sum(len(group) for group in audio_segments_groups)
            if total_segments == 0:
                print("æœªè·å¾—ä»»ä½•è½¬å½•ç»“æœ")
                translator.cleanup_temp_files(audio_chunks)
                return None

            print(f"è½¬å½•å®Œæˆï¼Œå…±è·å¾— {total_segments} ä¸ªè¯­éŸ³æ®µè½ï¼Œåˆ†å¸ƒåœ¨ {len(audio_segments_groups)} ä¸ªéŸ³é¢‘æ®µä¸­")

            # ç¿»è¯‘è½¬å½•ç»“æœ - æŒ‰éŸ³é¢‘æ®µåˆ†æ‰¹ç¿»è¯‘
            print("ğŸŒ å¼€å§‹ç¿»è¯‘è½¬å½•æ–‡æœ¬...")

            translated_segments_groups = []

            for i, segments_group in enumerate(audio_segments_groups):
                if not segments_group:  # è·³è¿‡ç©ºçš„åˆ†ç»„
                    translated_segments_groups.append([])
                    continue

                print(f"æ­£åœ¨ç¿»è¯‘ç¬¬ {i + 1}/{len(audio_segments_groups)} ä¸ªéŸ³é¢‘æ®µï¼ŒåŒ…å« {len(segments_group)} æ¡å­—å¹•...")

                # æå–å½“å‰éŸ³é¢‘æ®µçš„æ–‡æœ¬
                texts = [segment['text'] for segment in segments_group]

                # åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰¹é‡ç¿»è¯‘è¿˜æ˜¯é€æ¡ç¿»è¯‘
                if len(texts) >= batch_min:
                    translated_texts = translator.subtitle_translator.translate_texts_batch(
                        api_key=api_key,
                        model=text_models,
                        texts=texts,
                        translation_type=translation_type
                    )
                else:
                    translated_texts = translator.subtitle_translator._translate_one_by_one(
                        api_key=api_key,
                        model=text_models,
                        texts=texts,
                        translation_type=translation_type,
                        max_retries=3
                    )

                # æ ¼å¼åŒ–ç¿»è¯‘ç»“æœå¹¶ä¿å­˜
                translated_segments = []
                for j, segment in enumerate(segments_group):
                    if j < len(translated_texts):
                        formatted_text = translator.subtitle_translator.format_translated_subtitle(
                            segment['text'], translated_texts[j], translation_type
                        )

                        translated_segment = segment.copy()
                        translated_segment['text'] = formatted_text
                        translated_segments.append(translated_segment)

                translated_segments_groups.append(translated_segments)
                time.sleep(0.5)  # é¿å…APIè¯·æ±‚è¿‡é¢‘

            # åˆå¹¶æ‰€æœ‰ç¿»è¯‘åçš„æ®µè½
            all_translated_segments = []
            for group in translated_segments_groups:
                all_translated_segments.extend(group)

            # è½¬æ¢ä¸ºSRTæ ¼å¼
            srt_subtitles = translator.segments_to_srt_format(all_translated_segments)

            # ç”ŸæˆSRTå†…å®¹
            srt_content = translator.subtitle_translator.generate_srt(srt_subtitles)

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            translator.cleanup_temp_files(audio_chunks)

        elif mode == "åªç¿»éŸ³é¢‘":
            audio_chunks = translator.extract_audio_chunks(video_path, chunk_duration=180)
            if not audio_chunks:
                print("éŸ³é¢‘æå–å¤±è´¥")
                return None

            # è½¬å½•æ‰€æœ‰éŸ³é¢‘æ®µï¼Œä¿æŒåˆ†æ®µç»“æ„
            audio_segments_groups = []
            for i, chunk_info in enumerate(audio_chunks):
                print(f"ğŸ¤ è½¬å½•ç¬¬ {i + 1}/{len(audio_chunks)} æ®µ...")

                segments = translator.transcribe_audio_chunk(
                    audio_models,
                    chunk_info['path'],
                    chunk_info['start_time']
                )

                if segments:
                    audio_segments_groups.append(segments)
                    print(f"  è·å¾— {len(segments)} ä¸ªè¯­éŸ³æ®µè½")
                else:
                    print("  è¯¥æ®µæ— è¯­éŸ³å†…å®¹")
                    audio_segments_groups.append([])  # ä¿æŒåˆ†ç»„ç»“æ„

            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„è½¬å½•ç»“æœ
            total_segments = sum(len(group) for group in audio_segments_groups)
            if total_segments == 0:
                print("æœªè·å¾—ä»»ä½•è½¬å½•ç»“æœ")
                translator.cleanup_temp_files(audio_chunks)
                return None

            print(f"è½¬å½•å®Œæˆï¼Œå…±è·å¾— {total_segments} ä¸ªè¯­éŸ³æ®µè½ï¼Œåˆ†å¸ƒåœ¨ {len(audio_segments_groups)} ä¸ªéŸ³é¢‘æ®µä¸­")

            # ç¿»è¯‘è½¬å½•ç»“æœ - æŒ‰éŸ³é¢‘æ®µåˆ†æ‰¹ç¿»è¯‘
            print("ğŸŒ å¼€å§‹ç¿»è¯‘è½¬å½•æ–‡æœ¬...")

            translated_segments_groups = []

            for i, segments_group in enumerate(audio_segments_groups):
                if not segments_group:  # è·³è¿‡ç©ºçš„åˆ†ç»„
                    translated_segments_groups.append([])
                    continue

                print(f"æ­£åœ¨ç¿»è¯‘ç¬¬ {i + 1}/{len(audio_segments_groups)} ä¸ªéŸ³é¢‘æ®µï¼ŒåŒ…å« {len(segments_group)} æ¡å­—å¹•...")

                # æå–å½“å‰éŸ³é¢‘æ®µçš„æ–‡æœ¬
                texts = [segment['text'] for segment in segments_group]

                # åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰¹é‡ç¿»è¯‘è¿˜æ˜¯é€æ¡ç¿»è¯‘
                if len(texts) >= batch_min:
                    translated_texts = translator.subtitle_translator.translate_texts_batch(
                        api_key=api_key,
                        model=text_models,
                        texts=texts,
                        translation_type=translation_type
                    )
                else:
                    translated_texts = translator.subtitle_translator._translate_one_by_one(
                        api_key=api_key,
                        model=text_models,
                        texts=texts,
                        translation_type=translation_type,
                        max_retries=3
                    )

                # æ ¼å¼åŒ–ç¿»è¯‘ç»“æœå¹¶ä¿å­˜
                translated_segments = []
                for j, segment in enumerate(segments_group):
                    if j < len(translated_texts):
                        formatted_text = translator.subtitle_translator.format_translated_subtitle(
                            segment['text'], translated_texts[j], translation_type
                        )

                        translated_segment = segment.copy()
                        translated_segment['text'] = formatted_text
                        translated_segments.append(translated_segment)

                translated_segments_groups.append(translated_segments)
                time.sleep(0.5)  # é¿å…APIè¯·æ±‚è¿‡é¢‘

            # åˆå¹¶æ‰€æœ‰ç¿»è¯‘åçš„æ®µè½
            all_translated_segments = []
            for group in translated_segments_groups:
                all_translated_segments.extend(group)

            # è½¬æ¢ä¸ºSRTæ ¼å¼
            srt_subtitles = translator.segments_to_srt_format(all_translated_segments)

            # ç”ŸæˆSRTå†…å®¹
            srt_content = translator.subtitle_translator.generate_srt(srt_subtitles)

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            translator.cleanup_temp_files(audio_chunks)

        else:
            print(mode)
            return {'error':'æ²¡æœ‰è¿™ä¸ªé€‰é¡¹'}

        # å†™å…¥æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(srt_content)

        print(f"âœ… å­—å¹•ç”ŸæˆæˆåŠŸ: {output_file}")
        return output_file

    except Exception as e:
        print(f"âŒ ç”Ÿæˆå­—å¹•æ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return None